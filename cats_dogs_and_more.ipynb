{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras as ks # neural network models\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# For working with images\n",
    "import cv2 as cv2\n",
    "import matplotlib.image as mpimg\n",
    "import tqdm\n",
    "\n",
    "# Potentially useful tools - you do not have to use these\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Convolution2D, MaxPooling2D, SeparableConv2D\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# You may not need all of these, and you may find it useful to set some extras\n",
    "\n",
    "CATEGORIES = ['airplane','car','cat','dog','flower','fruit','motorbike','person']\n",
    "\n",
    "IMG_WIDTH = 100\n",
    "IMG_HEIGHT = 100\n",
    "TRAIN_PATH = '../input/natural_images/natural_images/'\n",
    "TEST_PATH = '../input/evaluate/evaluate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane_0372.jpg</td>\n",
       "      <td>airplane/airplane_0372.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane_0045.jpg</td>\n",
       "      <td>airplane/airplane_0045.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane_0075.jpg</td>\n",
       "      <td>airplane/airplane_0075.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane_0667.jpg</td>\n",
       "      <td>airplane/airplane_0667.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane_0620.jpg</td>\n",
       "      <td>airplane/airplane_0620.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class           filename                    file_loc\n",
       "0  airplane  airplane_0372.jpg  airplane/airplane_0372.jpg\n",
       "1  airplane  airplane_0045.jpg  airplane/airplane_0045.jpg\n",
       "2  airplane  airplane_0075.jpg  airplane/airplane_0075.jpg\n",
       "3  airplane  airplane_0667.jpg  airplane/airplane_0667.jpg\n",
       "4  airplane  airplane_0620.jpg  airplane/airplane_0620.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find data:\n",
    "folders = os.listdir(TRAIN_PATH)\n",
    "\n",
    "images = []\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(TRAIN_PATH + folder)\n",
    "    images += [(folder, file, folder + '/' + file) for file in files]\n",
    "\n",
    "image_locs = pd.DataFrame(images, columns=('class','filename','file_loc'))\n",
    "\n",
    "# data structure is three-column table\n",
    "# first column is class, second column is filename, third column is image address relative to TRAIN_PATH\n",
    "image_locs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over to you\n",
    "\n",
    "Now you must create your own solution to the problem. To get the file containing your results, you have to `commit` the kernel and then navigate to [kaggle.com/kernels](https://www.kaggle.com/kernels/), and the 'Your Work' tab, where you will find a list of your notebooks. Click on it and scroll down to the `Output` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6699, 3)\n",
      "Index(['person', 'motorbike', 'fruit', 'flower', 'dog', 'cat', 'car',\n",
      "       'airplane'],\n",
      "      dtype='object', name='class')\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "NUM_CLASSES = 8\n",
    "print(image_locs.shape)\n",
    "# Get a list of all the unique classes\n",
    "filter_classes = (image_locs.groupby(['class']).count().sort_values(['class'], ascending=False).head(NUM_CLASSES).index)\n",
    "print(filter_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       airplane\n",
      "1       airplane\n",
      "2       airplane\n",
      "3       airplane\n",
      "4       airplane\n",
      "          ...   \n",
      "6694       fruit\n",
      "6695       fruit\n",
      "6696       fruit\n",
      "6697       fruit\n",
      "6698       fruit\n",
      "Name: class, Length: 6699, dtype: object\n",
      "      airplane  car  cat  dog  flower  fruit  motorbike  person\n",
      "0            1    0    0    0       0      0          0       0\n",
      "1            1    0    0    0       0      0          0       0\n",
      "2            1    0    0    0       0      0          0       0\n",
      "3            1    0    0    0       0      0          0       0\n",
      "4            1    0    0    0       0      0          0       0\n",
      "...        ...  ...  ...  ...     ...    ...        ...     ...\n",
      "6694         0    0    0    0       0      1          0       0\n",
      "6695         0    0    0    0       0      1          0       0\n",
      "6696         0    0    0    0       0      1          0       0\n",
      "6697         0    0    0    0       0      1          0       0\n",
      "6698         0    0    0    0       0      1          0       0\n",
      "\n",
      "[6699 rows x 8 columns]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "img_locs_labels = image_locs['class']\n",
    "print(img_locs_labels)\n",
    "targets = pd.Series(img_locs_labels)\n",
    "one_hot = pd.get_dummies(targets, sparse=True, dummy_na=False)\n",
    "print(one_hot)\n",
    "one_hot_labels = np.asarray(one_hot)\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "data = np.array(filter_classes)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(data.reshape(-1,1))\n",
    "\n",
    "print(onehot_encoded)\n",
    "print(len(onehot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform the one hot encode back to its original label\n",
    "# This will be used for transforming predictions in actual labels\n",
    "def one_hot_to_label(prediction):\n",
    "#     print(prediction)\n",
    "#     k = 0\n",
    "    for i in range(0, len(onehot_encoded)):\n",
    "        if np.array_equal(prediction, onehot_encoded[i]):\n",
    "            break\n",
    "#         k = k + 1\n",
    "    return filter_classes[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In The Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test):\n",
    "    img = cv2.imread(train_or_test + format(img_id))\n",
    "    return cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6699\n",
      "6699\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "image_ids = []\n",
    "classes = []\n",
    "\n",
    "image_ids = image_locs['file_loc']\n",
    "\n",
    "classes = image_locs['class'].tolist()\n",
    "\n",
    "print(len(classes))\n",
    "\n",
    "for img_id in image_ids:\n",
    "  images.append(read_img(img_id, TRAIN_PATH))\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data Into Training/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane/airplane_0372.jpg' 'airplane/airplane_0045.jpg'\n",
      " 'airplane/airplane_0075.jpg' ... 'fruit/fruit_0496.jpg'\n",
      " 'fruit/fruit_0329.jpg' 'fruit/fruit_0880.jpg']\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "(5024,)\n",
      "(1675,)\n",
      "(5024, 8)\n",
      "(1675, 8)\n"
     ]
    }
   ],
   "source": [
    "# convert to np array\n",
    "X = np.array(image_ids)\n",
    "Y = np.array(one_hot_labels)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# Split data\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25, random_state=45)\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images for x train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5024\n",
      "1675\n"
     ]
    }
   ],
   "source": [
    "x_train_images = []\n",
    "x_test_images = []\n",
    "\n",
    "for img_id in train_x:\n",
    "  x_train_images.append(read_img(img_id, TRAIN_PATH))\n",
    "  \n",
    "for img_id in test_x:\n",
    "  x_test_images.append(read_img(img_id, TRAIN_PATH))\n",
    "\n",
    "print(len(x_train_images))\n",
    "print(len(x_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD THE MODEL\n",
    "def create_model():\n",
    "    # Channels first tells the pooling layer to use the (Height, Width, Depth) format instead of the (Depth, Height, Width)\n",
    "    data_format=\"channels_first\"\n",
    "    # Create a sequential model\n",
    "    model = Sequential()\n",
    "    # A convolutional layer\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "    # Activation layer\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling layer \n",
    "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
    "    #Add another convolution layer \n",
    "    model.add(Conv2D(32, (3,3), input_shape=(IMG_WIDTH, IMG_HEIGHT,3)))\n",
    "    #Add another relu activation\n",
    "    model.add(Activation('relu'))\n",
    "    #Add max pooling\n",
    "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #Add another convolution layer\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "    #Add another activation of relu\n",
    "    model.add(Activation('relu'))\n",
    "    #Add a max pooling layer\n",
    "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # Flatten Squashes the output of the previous layer to an array with 1 dimension\n",
    "    model.add(Flatten())\n",
    "    # A dense layer\n",
    "    model.add(Dense(64))\n",
    "    #Add another activation of relu \n",
    "    model.add(Activation('relu'))\n",
    "    #Add dropout\n",
    "    model.add(Dropout(0.1))\n",
    "    #  Dense layer - last layer must be equal to the number of classes\n",
    "    model.add(Dense(8))\n",
    "    model.add(BatchNormalization())\n",
    "    # Add an activation Sigmoid\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer = 'sgd', \n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to np array\n",
    "x_train_images_np = np.array(x_train_images)\n",
    "x_test_images_np = np.array(x_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5024 samples, validate on 1675 samples\n",
      "Epoch 1/100\n",
      "5024/5024 [==============================] - 4s 847us/step - loss: 0.6472 - acc: 0.6324 - val_loss: 0.5761 - val_acc: 0.7113\n",
      "Epoch 2/100\n",
      "5024/5024 [==============================] - 2s 362us/step - loss: 0.5716 - acc: 0.7211 - val_loss: 0.5408 - val_acc: 0.7609\n",
      "Epoch 3/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.5385 - acc: 0.7673 - val_loss: 0.5239 - val_acc: 0.7790\n",
      "Epoch 4/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.5151 - acc: 0.8006 - val_loss: 0.4997 - val_acc: 0.8137\n",
      "Epoch 5/100\n",
      "5024/5024 [==============================] - 2s 356us/step - loss: 0.4938 - acc: 0.8257 - val_loss: 0.4878 - val_acc: 0.8436\n",
      "Epoch 6/100\n",
      "5024/5024 [==============================] - 2s 352us/step - loss: 0.4752 - acc: 0.8470 - val_loss: 0.4649 - val_acc: 0.8685\n",
      "Epoch 7/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.4600 - acc: 0.8634 - val_loss: 0.4516 - val_acc: 0.8834\n",
      "Epoch 8/100\n",
      "5024/5024 [==============================] - 2s 348us/step - loss: 0.4453 - acc: 0.8751 - val_loss: 0.4381 - val_acc: 0.8851\n",
      "Epoch 9/100\n",
      "5024/5024 [==============================] - 2s 375us/step - loss: 0.4308 - acc: 0.8886 - val_loss: 0.4305 - val_acc: 0.8948\n",
      "Epoch 10/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.4177 - acc: 0.9012 - val_loss: 0.4129 - val_acc: 0.9125\n",
      "Epoch 11/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.4053 - acc: 0.9094 - val_loss: 0.4032 - val_acc: 0.9179\n",
      "Epoch 12/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.3952 - acc: 0.9154 - val_loss: 0.3877 - val_acc: 0.9263\n",
      "Epoch 13/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.3819 - acc: 0.9272 - val_loss: 0.3780 - val_acc: 0.9313\n",
      "Epoch 14/100\n",
      "5024/5024 [==============================] - 2s 361us/step - loss: 0.3722 - acc: 0.9324 - val_loss: 0.3688 - val_acc: 0.9366\n",
      "Epoch 15/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.3627 - acc: 0.9371 - val_loss: 0.3611 - val_acc: 0.9388\n",
      "Epoch 16/100\n",
      "5024/5024 [==============================] - 2s 351us/step - loss: 0.3530 - acc: 0.9429 - val_loss: 0.3544 - val_acc: 0.9416\n",
      "Epoch 17/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.3444 - acc: 0.9454 - val_loss: 0.3517 - val_acc: 0.9419\n",
      "Epoch 18/100\n",
      "5024/5024 [==============================] - 2s 361us/step - loss: 0.3359 - acc: 0.9513 - val_loss: 0.3381 - val_acc: 0.9482\n",
      "Epoch 19/100\n",
      "5024/5024 [==============================] - 2s 356us/step - loss: 0.3279 - acc: 0.9539 - val_loss: 0.3313 - val_acc: 0.9478\n",
      "Epoch 20/100\n",
      "5024/5024 [==============================] - 2s 353us/step - loss: 0.3194 - acc: 0.9562 - val_loss: 0.3253 - val_acc: 0.9518\n",
      "Epoch 21/100\n",
      "5024/5024 [==============================] - 2s 371us/step - loss: 0.3136 - acc: 0.9587 - val_loss: 0.3316 - val_acc: 0.9455\n",
      "Epoch 22/100\n",
      "5024/5024 [==============================] - 2s 364us/step - loss: 0.3064 - acc: 0.9614 - val_loss: 0.3103 - val_acc: 0.9549\n",
      "Epoch 23/100\n",
      "5024/5024 [==============================] - 2s 346us/step - loss: 0.2993 - acc: 0.9638 - val_loss: 0.3027 - val_acc: 0.9593\n",
      "Epoch 24/100\n",
      "5024/5024 [==============================] - 2s 356us/step - loss: 0.2930 - acc: 0.9659 - val_loss: 0.2977 - val_acc: 0.9607\n",
      "Epoch 25/100\n",
      "5024/5024 [==============================] - 2s 361us/step - loss: 0.2868 - acc: 0.9680 - val_loss: 0.2893 - val_acc: 0.9613\n",
      "Epoch 26/100\n",
      "5024/5024 [==============================] - 2s 353us/step - loss: 0.2813 - acc: 0.9695 - val_loss: 0.2895 - val_acc: 0.9614\n",
      "Epoch 27/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.2758 - acc: 0.9707 - val_loss: 0.2959 - val_acc: 0.9537\n",
      "Epoch 28/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.2704 - acc: 0.9727 - val_loss: 0.2790 - val_acc: 0.9646\n",
      "Epoch 29/100\n",
      "5024/5024 [==============================] - 2s 357us/step - loss: 0.2639 - acc: 0.9742 - val_loss: 0.2731 - val_acc: 0.9634\n",
      "Epoch 30/100\n",
      "5024/5024 [==============================] - 2s 360us/step - loss: 0.2588 - acc: 0.9755 - val_loss: 0.2673 - val_acc: 0.9654\n",
      "Epoch 31/100\n",
      "5024/5024 [==============================] - 2s 344us/step - loss: 0.2554 - acc: 0.9760 - val_loss: 0.2694 - val_acc: 0.9664\n",
      "Epoch 32/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.2490 - acc: 0.9783 - val_loss: 0.2576 - val_acc: 0.9676\n",
      "Epoch 33/100\n",
      "5024/5024 [==============================] - 2s 353us/step - loss: 0.2456 - acc: 0.9786 - val_loss: 0.2603 - val_acc: 0.9604\n",
      "Epoch 34/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.2405 - acc: 0.9792 - val_loss: 0.2543 - val_acc: 0.9659\n",
      "Epoch 35/100\n",
      "5024/5024 [==============================] - 2s 364us/step - loss: 0.2367 - acc: 0.9805 - val_loss: 0.2491 - val_acc: 0.9693\n",
      "Epoch 36/100\n",
      "5024/5024 [==============================] - 2s 360us/step - loss: 0.2346 - acc: 0.9791 - val_loss: 0.2413 - val_acc: 0.9704\n",
      "Epoch 37/100\n",
      "5024/5024 [==============================] - 2s 357us/step - loss: 0.2287 - acc: 0.9817 - val_loss: 0.2382 - val_acc: 0.9703\n",
      "Epoch 38/100\n",
      "5024/5024 [==============================] - 2s 357us/step - loss: 0.2253 - acc: 0.9818 - val_loss: 0.2384 - val_acc: 0.9666\n",
      "Epoch 39/100\n",
      "5024/5024 [==============================] - 2s 357us/step - loss: 0.2213 - acc: 0.9832 - val_loss: 0.2366 - val_acc: 0.9701\n",
      "Epoch 40/100\n",
      "5024/5024 [==============================] - 2s 367us/step - loss: 0.2177 - acc: 0.9843 - val_loss: 0.2294 - val_acc: 0.9704\n",
      "Epoch 41/100\n",
      "5024/5024 [==============================] - 2s 379us/step - loss: 0.2141 - acc: 0.9844 - val_loss: 0.2301 - val_acc: 0.9710\n",
      "Epoch 42/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.2103 - acc: 0.9845 - val_loss: 0.2293 - val_acc: 0.9686\n",
      "Epoch 43/100\n",
      "5024/5024 [==============================] - 2s 352us/step - loss: 0.2077 - acc: 0.9854 - val_loss: 0.2202 - val_acc: 0.9710\n",
      "Epoch 44/100\n",
      "5024/5024 [==============================] - 2s 368us/step - loss: 0.2050 - acc: 0.9857 - val_loss: 0.2379 - val_acc: 0.9662\n",
      "Epoch 45/100\n",
      "5024/5024 [==============================] - 2s 351us/step - loss: 0.2015 - acc: 0.9862 - val_loss: 0.2208 - val_acc: 0.9713\n",
      "Epoch 46/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.1987 - acc: 0.9858 - val_loss: 0.2143 - val_acc: 0.9699\n",
      "Epoch 47/100\n",
      "5024/5024 [==============================] - 2s 348us/step - loss: 0.1965 - acc: 0.9860 - val_loss: 0.2134 - val_acc: 0.9677\n",
      "Epoch 48/100\n",
      "5024/5024 [==============================] - 2s 362us/step - loss: 0.1925 - acc: 0.9880 - val_loss: 0.2151 - val_acc: 0.9691\n",
      "Epoch 49/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.1898 - acc: 0.9876 - val_loss: 0.2065 - val_acc: 0.9713\n",
      "Epoch 50/100\n",
      "5024/5024 [==============================] - 2s 366us/step - loss: 0.1863 - acc: 0.9891 - val_loss: 0.2051 - val_acc: 0.9719\n",
      "Epoch 51/100\n",
      "5024/5024 [==============================] - 2s 371us/step - loss: 0.1836 - acc: 0.9891 - val_loss: 0.1999 - val_acc: 0.9722\n",
      "Epoch 52/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.1817 - acc: 0.9887 - val_loss: 0.1993 - val_acc: 0.9717\n",
      "Epoch 53/100\n",
      "5024/5024 [==============================] - 2s 353us/step - loss: 0.1802 - acc: 0.9893 - val_loss: 0.1995 - val_acc: 0.9725\n",
      "Epoch 54/100\n",
      "5024/5024 [==============================] - 2s 370us/step - loss: 0.1771 - acc: 0.9896 - val_loss: 0.1966 - val_acc: 0.9726\n",
      "Epoch 55/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.1743 - acc: 0.9905 - val_loss: 0.1996 - val_acc: 0.9695\n",
      "Epoch 56/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.1710 - acc: 0.9906 - val_loss: 0.2262 - val_acc: 0.9568\n",
      "Epoch 57/100\n",
      "5024/5024 [==============================] - 2s 357us/step - loss: 0.1705 - acc: 0.9903 - val_loss: 0.1904 - val_acc: 0.9734\n",
      "Epoch 58/100\n",
      "5024/5024 [==============================] - 2s 347us/step - loss: 0.1679 - acc: 0.9908 - val_loss: 0.1889 - val_acc: 0.9734\n",
      "Epoch 59/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.1654 - acc: 0.9910 - val_loss: 0.1979 - val_acc: 0.9693\n",
      "Epoch 60/100\n",
      "5024/5024 [==============================] - 2s 369us/step - loss: 0.1635 - acc: 0.9916 - val_loss: 0.1851 - val_acc: 0.9725\n",
      "Epoch 61/100\n",
      "5024/5024 [==============================] - 2s 360us/step - loss: 0.1612 - acc: 0.9918 - val_loss: 0.1879 - val_acc: 0.9707\n",
      "Epoch 62/100\n",
      "5024/5024 [==============================] - 2s 365us/step - loss: 0.1585 - acc: 0.9929 - val_loss: 0.1831 - val_acc: 0.9722\n",
      "Epoch 63/100\n",
      "5024/5024 [==============================] - 2s 364us/step - loss: 0.1564 - acc: 0.9927 - val_loss: 0.1808 - val_acc: 0.9716\n",
      "Epoch 64/100\n",
      "5024/5024 [==============================] - 2s 342us/step - loss: 0.1550 - acc: 0.9928 - val_loss: 0.1769 - val_acc: 0.9727\n",
      "Epoch 65/100\n",
      "5024/5024 [==============================] - 2s 364us/step - loss: 0.1542 - acc: 0.9918 - val_loss: 0.1771 - val_acc: 0.9729\n",
      "Epoch 66/100\n",
      "5024/5024 [==============================] - 2s 344us/step - loss: 0.1516 - acc: 0.9928 - val_loss: 0.1795 - val_acc: 0.9728\n",
      "Epoch 67/100\n",
      "5024/5024 [==============================] - 2s 368us/step - loss: 0.1497 - acc: 0.9926 - val_loss: 0.1786 - val_acc: 0.9716\n",
      "Epoch 68/100\n",
      "5024/5024 [==============================] - 2s 341us/step - loss: 0.1474 - acc: 0.9935 - val_loss: 0.1762 - val_acc: 0.9716\n",
      "Epoch 69/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.1466 - acc: 0.9929 - val_loss: 0.1704 - val_acc: 0.9725\n",
      "Epoch 70/100\n",
      "5024/5024 [==============================] - 2s 366us/step - loss: 0.1444 - acc: 0.9937 - val_loss: 0.1701 - val_acc: 0.9731\n",
      "Epoch 71/100\n",
      "5024/5024 [==============================] - 2s 343us/step - loss: 0.1424 - acc: 0.9940 - val_loss: 0.1715 - val_acc: 0.9719\n",
      "Epoch 72/100\n",
      "5024/5024 [==============================] - 2s 365us/step - loss: 0.1411 - acc: 0.9940 - val_loss: 0.1860 - val_acc: 0.9654\n",
      "Epoch 73/100\n",
      "5024/5024 [==============================] - 2s 433us/step - loss: 0.1398 - acc: 0.9942 - val_loss: 0.1676 - val_acc: 0.9722\n",
      "Epoch 74/100\n",
      "5024/5024 [==============================] - 2s 392us/step - loss: 0.1383 - acc: 0.9934 - val_loss: 0.1676 - val_acc: 0.9703\n",
      "Epoch 75/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.1366 - acc: 0.9944 - val_loss: 0.1694 - val_acc: 0.9679\n",
      "Epoch 76/100\n",
      "5024/5024 [==============================] - 2s 349us/step - loss: 0.1347 - acc: 0.9945 - val_loss: 0.1690 - val_acc: 0.9714\n",
      "Epoch 77/100\n",
      "5024/5024 [==============================] - 2s 352us/step - loss: 0.1340 - acc: 0.9943 - val_loss: 0.1656 - val_acc: 0.9711\n",
      "Epoch 78/100\n",
      "5024/5024 [==============================] - 2s 346us/step - loss: 0.1313 - acc: 0.9952 - val_loss: 0.1613 - val_acc: 0.9720\n",
      "Epoch 79/100\n",
      "5024/5024 [==============================] - 2s 354us/step - loss: 0.1313 - acc: 0.9949 - val_loss: 0.1664 - val_acc: 0.9720\n",
      "Epoch 80/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.1304 - acc: 0.9944 - val_loss: 0.1578 - val_acc: 0.9739\n",
      "Epoch 81/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.1267 - acc: 0.9958 - val_loss: 0.1563 - val_acc: 0.9732\n",
      "Epoch 82/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.1264 - acc: 0.9959 - val_loss: 0.1596 - val_acc: 0.9713\n",
      "Epoch 83/100\n",
      "5024/5024 [==============================] - 2s 356us/step - loss: 0.1242 - acc: 0.9958 - val_loss: 0.1591 - val_acc: 0.9724\n",
      "Epoch 84/100\n",
      "5024/5024 [==============================] - 2s 358us/step - loss: 0.1237 - acc: 0.9957 - val_loss: 0.1570 - val_acc: 0.9728\n",
      "Epoch 85/100\n",
      "5024/5024 [==============================] - 2s 363us/step - loss: 0.1226 - acc: 0.9960 - val_loss: 0.1528 - val_acc: 0.9728\n",
      "Epoch 86/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.1217 - acc: 0.9956 - val_loss: 0.1525 - val_acc: 0.9743\n",
      "Epoch 87/100\n",
      "5024/5024 [==============================] - 2s 355us/step - loss: 0.1201 - acc: 0.9956 - val_loss: 0.1502 - val_acc: 0.9744\n",
      "Epoch 88/100\n",
      "5024/5024 [==============================] - 2s 352us/step - loss: 0.1192 - acc: 0.9959 - val_loss: 0.1535 - val_acc: 0.9724\n",
      "Epoch 89/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.1178 - acc: 0.9958 - val_loss: 0.1511 - val_acc: 0.9730\n",
      "Epoch 90/100\n",
      "5024/5024 [==============================] - 2s 364us/step - loss: 0.1158 - acc: 0.9968 - val_loss: 0.1496 - val_acc: 0.9731\n",
      "Epoch 91/100\n",
      "5024/5024 [==============================] - 2s 363us/step - loss: 0.1150 - acc: 0.9965 - val_loss: 0.1510 - val_acc: 0.9728\n",
      "Epoch 92/100\n",
      "5024/5024 [==============================] - 2s 359us/step - loss: 0.1149 - acc: 0.9960 - val_loss: 0.1518 - val_acc: 0.9722\n",
      "Epoch 93/100\n",
      "5024/5024 [==============================] - 2s 352us/step - loss: 0.1126 - acc: 0.9971 - val_loss: 0.1525 - val_acc: 0.9707\n",
      "Epoch 94/100\n",
      "5024/5024 [==============================] - 2s 344us/step - loss: 0.1120 - acc: 0.9964 - val_loss: 0.1458 - val_acc: 0.9739\n",
      "Epoch 95/100\n",
      "5024/5024 [==============================] - 2s 354us/step - loss: 0.1110 - acc: 0.9963 - val_loss: 0.1464 - val_acc: 0.9740\n",
      "Epoch 96/100\n",
      "5024/5024 [==============================] - 2s 354us/step - loss: 0.1109 - acc: 0.9965 - val_loss: 0.1443 - val_acc: 0.9739\n",
      "Epoch 97/100\n",
      "5024/5024 [==============================] - 2s 348us/step - loss: 0.1094 - acc: 0.9967 - val_loss: 0.1454 - val_acc: 0.9722\n",
      "Epoch 98/100\n",
      "5024/5024 [==============================] - 2s 350us/step - loss: 0.1089 - acc: 0.9964 - val_loss: 0.1455 - val_acc: 0.9734\n",
      "Epoch 99/100\n",
      "5024/5024 [==============================] - 2s 361us/step - loss: 0.1078 - acc: 0.9963 - val_loss: 0.1456 - val_acc: 0.9719\n",
      "Epoch 100/100\n",
      "5024/5024 [==============================] - 2s 354us/step - loss: 0.1057 - acc: 0.9971 - val_loss: 0.1408 - val_acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6824119f60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "'''\n",
    "epocs = 100\n",
    "batch size = 50\n",
    "'''\n",
    "model.fit(x_train_images_np, train_y, epochs=100, batch_size=50, validation_data=(x_test_images_np, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1675/1675 [==============================] - 0s 161us/step\n",
      "[0.1407877215698584, 0.9737313434259215]\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels on the test set\n",
    "# print(x_test_images_np)\n",
    "predictions = model.predict(x_test_images_np)\n",
    "# print(predictions)\n",
    "print(model.evaluate(x_test_images_np, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Predictions Against Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: flower\n",
      "Actual Label: flower\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: dog\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: motorbike\n",
      "Actual Label: motorbike\n",
      "----\n",
      "Pred: motorbike\n",
      "Actual Label: motorbike\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: dog\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: car\n",
      "Actual Label: car\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: car\n",
      "Actual Label: car\n",
      "----\n",
      "Pred: car\n",
      "Actual Label: car\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: dog\n",
      "Actual Label: dog\n",
      "----\n",
      "Pred: motorbike\n",
      "Actual Label: motorbike\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: flower\n",
      "Actual Label: flower\n",
      "----\n",
      "Pred: dog\n",
      "Actual Label: dog\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: car\n",
      "Actual Label: car\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: car\n",
      "Actual Label: car\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: motorbike\n",
      "Actual Label: motorbike\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: cat\n",
      "----\n",
      "Pred: fruit\n",
      "Actual Label: fruit\n",
      "----\n",
      "Pred: airplane\n",
      "Actual Label: airplane\n",
      "----\n",
      "Pred: cat\n",
      "Actual Label: dog\n",
      "----\n",
      "Pred: person\n",
      "Actual Label: person\n",
      "----\n",
      "Pred: motorbike\n",
      "Actual Label: motorbike\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "IMAGES_TO_PLOT = 50\n",
    "i = 0\n",
    "predictions = (predictions == predictions.max(axis=1)[:,None]).astype(int)\n",
    "for img in x_test_images[0:IMAGES_TO_PLOT]:\n",
    "    print(\"Pred: \" + one_hot_to_label(predictions[i]))\n",
    "    print('Actual Label: ' + one_hot_to_label(test_y[i]))\n",
    "    print('----')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Against Unlabelled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.jpg</td>\n",
       "      <td>39.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150.jpg</td>\n",
       "      <td>150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199.jpg</td>\n",
       "      <td>199.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146.jpg</td>\n",
       "      <td>146.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129.jpg</td>\n",
       "      <td>129.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename file_loc\n",
       "0   39.jpg   39.jpg\n",
       "1  150.jpg  150.jpg\n",
       "2  199.jpg  199.jpg\n",
       "3  146.jpg  146.jpg\n",
       "4  129.jpg  129.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders1 = os.listdir(TEST_PATH)\n",
    "images1 = []\n",
    "\n",
    "for folder1 in folders1:\n",
    "    files1 = os.listdir(TEST_PATH )\n",
    "    images1 += [(file1, file1) for file1 in files1]\n",
    "\n",
    "image_locs1 = pd.DataFrame(images1, columns=('filename','file_loc'))\n",
    "image_locs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example values:\n",
    "# filenames = ['test001','test002','test003','test004']\n",
    "# predictions = ['car','cat','fruit','motorbike']\n",
    "new_images = []\n",
    "new_image_locs = image_locs1['file_loc']\n",
    "new_image_names = image_locs1['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(len(new_image_names))\n",
    "\n",
    "for img_id in new_image_locs:\n",
    "    new_images.append(read_img(img_id, TEST_PATH))\n",
    "\n",
    "print(len(new_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " new_images_np = np.array(new_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_predictions = model.predict(new_images_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: car\n",
      "----\n",
      "Pred: flower\n",
      "----\n",
      "Pred: person\n",
      "----\n",
      "Pred: flower\n",
      "----\n",
      "Pred: motorbike\n",
      "----\n",
      "Pred: car\n",
      "----\n",
      "Pred: airplane\n",
      "----\n",
      "Pred: fruit\n",
      "----\n",
      "Pred: airplane\n",
      "----\n",
      "Pred: cat\n",
      "----\n",
      "Pred: flower\n",
      "----\n",
      "Pred: flower\n",
      "----\n",
      "Pred: airplane\n",
      "----\n",
      "Pred: dog\n",
      "----\n",
      "Pred: motorbike\n",
      "----\n",
      "Pred: person\n",
      "----\n",
      "Pred: airplane\n",
      "----\n",
      "Pred: motorbike\n",
      "----\n",
      "Pred: car\n",
      "----\n",
      "Pred: car\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "RESULTS_TO_CHECK = 20\n",
    "i = 0\n",
    "new_img_predictions = (new_img_predictions == new_img_predictions.max(axis=1)[:,None]).astype(int)\n",
    "for img in new_images[0:RESULTS_TO_CHECK]:\n",
    "    print(\"Pred: \" + one_hot_to_label(new_img_predictions[i]))\n",
    "    print('----')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_one_hot = []\n",
    "\n",
    "for pred in new_img_predictions:\n",
    "    label = one_hot_to_label(pred)\n",
    "    pred_one_hot.append(label)\n",
    "    \n",
    "# print(pred_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "# results go in dataframe: first column is image filename, second column is category name\n",
    "# category names are: airplane, car, cat, dog, flower, fruit, motorbike, person\n",
    "df = pd.DataFrame()\n",
    "df['filename'] = new_image_names\n",
    "df['label'] = pred_one_hot\n",
    "df = df.sort_values(by='filename')\n",
    "df2 = df.drop_duplicates(keep=\"first\")\n",
    "df2.head()\n",
    "df2.to_csv('results.csv', header=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
